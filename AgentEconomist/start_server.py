#!/usr/bin/env python3
"""
LangGraph Server å¯åŠ¨è„šæœ¬
ä½¿ç”¨ FastAPI å¯åŠ¨ LangGraph Agent æœåŠ¡ï¼ˆPython 3.11+ï¼‰
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from langgraph.graph import CompiledGraph
from langgraph.checkpoint.memory import MemorySaver

from AgentEconomist.graph.agent import build_economist_graph
from AgentEconomist.config import Config

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(title="Agent Economist API")

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ç¼–è¯‘ graph
checkpointer = MemorySaver()
graph: CompiledGraph = build_economist_graph()

@app.get("/")
async def root():
    return {
        "status": "running",
        "service": "Agent Economist",
        "version": "1.0.0"
    }

@app.get("/health")
async def health():
    return {"status": "healthy"}

# LangGraph API å…¼å®¹ç«¯ç‚¹
@app.post("/threads/{thread_id}/runs")
async def create_run(thread_id: str, request: dict):
    """åˆ›å»ºå¹¶è¿è¡Œä¸€ä¸ª thread"""
    config = {"configurable": {"thread_id": thread_id}}
    
    # ä»è¯·æ±‚ä¸­æå–æ¶ˆæ¯
    messages = request.get("input", {}).get("messages", [])
    if not messages:
        return {"error": "No messages provided"}
    
    # è°ƒç”¨ graph
    result = graph.invoke({"messages": messages}, config=config)
    
    return {
        "run_id": f"run_{thread_id}",
        "status": "success",
        "result": result
    }

@app.get("/threads/{thread_id}/state")
async def get_state(thread_id: str):
    """è·å– thread çš„çŠ¶æ€"""
    config = {"configurable": {"thread_id": thread_id}}
    state = graph.get_state(config)
    
    return {
        "thread_id": thread_id,
        "state": {
            "values": state.values if hasattr(state, "values") else {},
            "next": state.next if hasattr(state, "next") else []
        }
    }

@app.post("/threads/{thread_id}/stream")
async def stream_run(thread_id: str, request: dict):
    """æµå¼è¿è¡Œï¼ˆç®€åŒ–ç‰ˆï¼Œè¿”å›å®Œæ•´ç»“æœï¼‰"""
    config = {"configurable": {"thread_id": thread_id}}
    messages = request.get("input", {}).get("messages", [])
    
    if not messages:
        return {"error": "No messages provided"}
    
    # æµå¼è°ƒç”¨
    events = []
    async for event in graph.astream({"messages": messages}, config=config):
        events.append(event)
    
    return {
        "events": events,
        "thread_id": thread_id
    }

if __name__ == "__main__":
    Config.validate()
    
    print("=" * 60)
    print("ğŸš€ Starting Agent Economist Server")
    print("=" * 60)
    print(f"ğŸ“ Project Root: {Config.PROJECT_ROOT}")
    print(f"ğŸŒ Server: {Config.LANGGRAPH_HOST}:{Config.LANGGRAPH_PORT}")
    print(f"ğŸ¤– Model: {Config.LLM_MODEL}")
    print("=" * 60)
    print("\nâœ… Server ready! Press Ctrl+C to stop.\n")
    
    uvicorn.run(
        app,
        host=Config.LANGGRAPH_HOST,
        port=Config.LANGGRAPH_PORT,
        log_level="info"
    )
