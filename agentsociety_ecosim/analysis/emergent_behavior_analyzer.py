"""
æ¶Œç°è¡Œä¸ºåˆ†æå™¨ - ç ”ç©¶ä¸ªä½“è¡Œä¸ºå¦‚ä½•å¯¼è‡´å®è§‚æ¨¡å¼

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¾®è§‚è¡Œä¸ºè¿½è¸ªï¼šè®°å½•æ¯ä¸ªæ™ºèƒ½ä½“çš„å†³ç­–å’Œè¡Œä¸º
2. å®è§‚æ¨¡å¼è¯†åˆ«ï¼šæ£€æµ‹ç³»ç»Ÿå±‚é¢çš„æ¶Œç°æ¨¡å¼
3. å¾®è§‚-å®è§‚æ˜ å°„ï¼šåˆ†æä¸ªä½“è¡Œä¸ºå¦‚ä½•èšåˆå½¢æˆå®è§‚æ¨¡å¼
4. æ¶Œç°æœºåˆ¶é‡åŒ–ï¼šè®¡ç®—æ¶Œç°å¼ºåº¦ã€ä¸´ç•Œç‚¹ç­‰æŒ‡æ ‡
5. è‡ªç»„ç»‡æ£€æµ‹ï¼šè¯†åˆ«è‡ªå‘å½¢æˆçš„ç»“æ„å’Œæ¨¡å¼

è¾“å‡ºåŒ…æ‹¬ï¼š
- æ¶Œç°æ¨¡å¼æŠ¥å‘Š
- å¾®è§‚-å®è§‚è¿æ¥åˆ†æ
- ç›¸å˜æ£€æµ‹ç»“æœ
- è‡ªç»„ç»‡ç»“æ„è¯†åˆ«
- å¯è§†åŒ–å›¾è¡¨
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from collections import defaultdict
import json
import os
from datetime import datetime
import matplotlib.pyplot as plt
try:
    import seaborn as sns
except ImportError:
    sns = None
from scipy import stats
from scipy.cluster.hierarchy import linkage, fcluster
from sklearn.decomposition import PCA
from sklearn.cluster import DBSCAN
import networkx as nx

from agentsociety_ecosim.utils.log_utils import setup_global_logger
logger = setup_global_logger(__name__)


@dataclass
class MicroBehavior:
    """å¾®è§‚è¡Œä¸ºè®°å½•"""
    agent_id: str
    agent_type: str  # 'household' or 'firm'
    timestamp: int  # month
    behavior_type: str  # 'consume', 'produce', 'hire', 'invest', etc.
    behavior_data: Dict[str, Any]  # å…·ä½“è¡Œä¸ºæ•°æ®
    context: Dict[str, Any]  # è¡Œä¸ºå‘ç”Ÿçš„ä¸Šä¸‹æ–‡


@dataclass
class MacroPattern:
    """å®è§‚æ¨¡å¼è¯†åˆ«ç»“æœ"""
    pattern_id: str
    pattern_type: str  # 'market_concentration', 'wealth_inequality', 'price_correlation', etc.
    emergence_month: int  # æ¨¡å¼å‡ºç°çš„æœˆä»½
    strength: float  # æ¨¡å¼å¼ºåº¦ (0-1)
    stability: float  # æ¨¡å¼ç¨³å®šæ€§ (0-1)
    micro_contributors: List[str]  # è´¡çŒ®è¯¥æ¨¡å¼çš„ä¸ªä½“IDåˆ—è¡¨
    macro_metrics: Dict[str, float]  # å®è§‚æŒ‡æ ‡
    description: str  # æ¨¡å¼æè¿°


@dataclass
class EmergenceMetrics:
    """æ¶Œç°æŒ‡æ ‡"""
    emergence_strength: float  # æ¶Œç°å¼ºåº¦
    critical_point: Optional[int]  # ä¸´ç•Œç‚¹ï¼ˆç›¸å˜å‘ç”Ÿçš„æœˆä»½ï¼‰
    order_parameter: float  # åºå‚é‡
    correlation_length: float  # å…³è”é•¿åº¦
    self_organization_index: float  # è‡ªç»„ç»‡æŒ‡æ•°


class EmergentBehaviorAnalyzer:
    """
    æ¶Œç°è¡Œä¸ºåˆ†æå™¨
    
    åˆ†æä¸ªä½“è¡Œä¸ºå¦‚ä½•å¯¼è‡´å®è§‚æ¨¡å¼ï¼Œè¯†åˆ«æ¶Œç°ç°è±¡å’Œè‡ªç»„ç»‡è¡Œä¸º
    """
    
    def __init__(self, output_dir: str = "output/emergent_behavior"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # æ•°æ®å­˜å‚¨
        self.micro_behaviors: List[MicroBehavior] = []
        self.macro_patterns: List[MacroPattern] = []
        self.monthly_aggregates: Dict[int, Dict[str, Any]] = {}
        
        # åˆ†æç»“æœ
        self.emergence_metrics: Dict[int, EmergenceMetrics] = {}
        self.phase_transitions: List[Dict[str, Any]] = []
        self.self_organizing_structures: List[Dict[str, Any]] = []
        
    def record_micro_behavior(
        self,
        agent_id: str,
        agent_type: str,
        month: int,
        behavior_type: str,
        behavior_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ):
        """è®°å½•å¾®è§‚è¡Œä¸º"""
        behavior = MicroBehavior(
            agent_id=agent_id,
            agent_type=agent_type,
            timestamp=month,
            behavior_type=behavior_type,
            behavior_data=behavior_data,
            context=context or {}
        )
        self.micro_behaviors.append(behavior)
    
    def analyze_emergence(self, current_month: int) -> Dict[str, Any]:
        """
        åˆ†ææ¶Œç°è¡Œä¸º
        
        è¾“å‡ºç»“æ„ï¼š
        {
            "emergence_report": {
                "patterns": [...],  # è¯†åˆ«çš„å®è§‚æ¨¡å¼
                "metrics": {...},   # æ¶Œç°æŒ‡æ ‡
                "phase_transitions": [...],  # ç›¸å˜æ£€æµ‹
                "self_organization": [...]   # è‡ªç»„ç»‡ç»“æ„
            },
            "micro_macro_mapping": {
                "pattern_id": {
                    "micro_contributors": [...],
                    "contribution_weights": {...},
                    "emergence_mechanism": "..."
                }
            },
            "visualizations": {
                "pattern_evolution": "path/to/chart.png",
                "phase_diagram": "path/to/chart.png",
                ...
            }
        }
        """
        logger.info(f"ğŸ”¬ å¼€å§‹åˆ†æç¬¬ {current_month} æœˆçš„æ¶Œç°è¡Œä¸º...")
        
        # 1. èšåˆå¾®è§‚è¡Œä¸ºåˆ°å®è§‚å±‚é¢
        monthly_aggregate = self._aggregate_micro_to_macro(current_month)
        self.monthly_aggregates[current_month] = monthly_aggregate
        
        # 2. è¯†åˆ«å®è§‚æ¨¡å¼
        patterns = self._detect_macro_patterns(current_month)
        self.macro_patterns.extend(patterns)
        
        # 3. è®¡ç®—æ¶Œç°æŒ‡æ ‡
        metrics = self._calculate_emergence_metrics(current_month)
        self.emergence_metrics[current_month] = metrics
        
        # 4. æ£€æµ‹ç›¸å˜
        phase_transitions = self._detect_phase_transitions(current_month)
        self.phase_transitions.extend(phase_transitions)
        
        # 5. è¯†åˆ«è‡ªç»„ç»‡ç»“æ„
        self_org_structures = self._detect_self_organization(current_month)
        self.self_organizing_structures.extend(self_org_structures)
        
        # 6. åˆ†æå¾®è§‚-å®è§‚æ˜ å°„
        micro_macro_mapping = self._analyze_micro_macro_mapping(patterns)
        
        # 7. ç”Ÿæˆå¯è§†åŒ–
        visualizations = self._generate_visualizations(current_month)
        
        # 8. ç”ŸæˆæŠ¥å‘Š
        report = {
            "month": current_month,
            "emergence_report": {
                "patterns": [self._pattern_to_dict(p) for p in patterns],
                "metrics": self._metrics_to_dict(metrics),
                "phase_transitions": phase_transitions,
                "self_organization": self_org_structures
            },
            "micro_macro_mapping": micro_macro_mapping,
            "visualizations": visualizations,
            "summary": self._generate_summary(patterns, metrics, phase_transitions)
        }
        
        # ä¿å­˜æŠ¥å‘Š
        self._save_report(report, current_month)
        
        logger.info(f"âœ… æ¶Œç°è¡Œä¸ºåˆ†æå®Œæˆï¼Œè¯†åˆ«äº† {len(patterns)} ä¸ªå®è§‚æ¨¡å¼")
        
        return report
    
    def _aggregate_micro_to_macro(self, month: int) -> Dict[str, Any]:
        """å°†å¾®è§‚è¡Œä¸ºèšåˆåˆ°å®è§‚å±‚é¢"""
        # ç­›é€‰å½“æœˆçš„å¾®è§‚è¡Œä¸º
        month_behaviors = [b for b in self.micro_behaviors if b.timestamp == month]
        
        aggregate = {
            "total_behaviors": len(month_behaviors),
            "behavior_distribution": defaultdict(int),
            "household_behaviors": [],
            "firm_behaviors": [],
            "aggregated_metrics": {}
        }
        
        # æŒ‰ç±»å‹åˆ†ç±»
        for behavior in month_behaviors:
            aggregate["behavior_distribution"][behavior.behavior_type] += 1
            
            if behavior.agent_type == "household":
                aggregate["household_behaviors"].append(behavior)
            elif behavior.agent_type == "firm":
                aggregate["firm_behaviors"].append(behavior)
        
        # è®¡ç®—èšåˆæŒ‡æ ‡
        # ä¾‹å¦‚ï¼šæ¶ˆè´¹æ€»é¢ã€ç”Ÿäº§æ€»é¢ã€å¹³å‡ä»·æ ¼ç­‰
        if aggregate["household_behaviors"]:
            total_consumption = sum(
                b.behavior_data.get("amount", 0) 
                for b in aggregate["household_behaviors"]
                if b.behavior_type == "consume"
            )
            aggregate["aggregated_metrics"]["total_consumption"] = total_consumption
        
        if aggregate["firm_behaviors"]:
            total_production = sum(
                b.behavior_data.get("quantity", 0)
                for b in aggregate["firm_behaviors"]
                if b.behavior_type == "produce"
            )
            aggregate["aggregated_metrics"]["total_production"] = total_production
        
        return aggregate
    
    def _detect_macro_patterns(self, month: int) -> List[MacroPattern]:
        """æ£€æµ‹å®è§‚æ¨¡å¼"""
        patterns = []
        
        # è·å–å†å²æ•°æ®ï¼ˆè‡³å°‘éœ€è¦3ä¸ªæœˆçš„æ•°æ®æ‰èƒ½æ£€æµ‹æ¨¡å¼ï¼‰
        if month < 3:
            return patterns
        
        # 1. å¸‚åœºé›†ä¸­åº¦æ¨¡å¼
        concentration_pattern = self._detect_market_concentration(month)
        if concentration_pattern:
            patterns.append(concentration_pattern)
        
        # 2. è´¢å¯Œä¸å¹³ç­‰æ¨¡å¼
        inequality_pattern = self._detect_wealth_inequality(month)
        if inequality_pattern:
            patterns.append(inequality_pattern)
        
        # 3. ä»·æ ¼ç›¸å…³æ€§æ¨¡å¼
        price_correlation_pattern = self._detect_price_correlation(month)
        if price_correlation_pattern:
            patterns.append(price_correlation_pattern)
        
        # 4. æ¶ˆè´¹é›†ç¾¤æ¨¡å¼
        consumption_cluster_pattern = self._detect_consumption_clusters(month)
        if consumption_cluster_pattern:
            patterns.append(consumption_cluster_pattern)
        
        # 5. åˆ›æ–°æ‰©æ•£æ¨¡å¼
        innovation_diffusion_pattern = self._detect_innovation_diffusion(month)
        if innovation_diffusion_pattern:
            patterns.append(innovation_diffusion_pattern)
        
        return patterns
    
    def _detect_market_concentration(self, month: int) -> Optional[MacroPattern]:
        """æ£€æµ‹å¸‚åœºé›†ä¸­åº¦æ¨¡å¼ï¼ˆå¯¡å¤´å„æ–­ã€å®Œå…¨ç«äº‰ç­‰ï¼‰"""
        # è·å–ä¼ä¸šå¸‚åœºä»½é¢æ•°æ®
        firm_behaviors = [b for b in self.micro_behaviors 
                         if b.timestamp == month and b.agent_type == "firm"]
        
        if not firm_behaviors:
            return None
        
        # è®¡ç®—å¸‚åœºä»½é¢
        revenues = {}
        for behavior in firm_behaviors:
            if behavior.behavior_type == "sell":
                firm_id = behavior.agent_id
                revenue = behavior.behavior_data.get("revenue", 0)
                revenues[firm_id] = revenues.get(firm_id, 0) + revenue
        
        if not revenues:
            return None
        
        total_revenue = sum(revenues.values())
        if total_revenue == 0:
            return None
        
        # è®¡ç®—HHIæŒ‡æ•°ï¼ˆHerfindahl-Hirschman Indexï¼‰
        market_shares = {firm_id: rev / total_revenue for firm_id, rev in revenues.items()}
        hhi = sum(share ** 2 for share in market_shares.values())
        
        # åˆ¤æ–­å¸‚åœºç»“æ„
        if hhi > 0.25:  # é«˜åº¦é›†ä¸­
            pattern_type = "high_market_concentration"
            strength = min(1.0, hhi / 0.5)  # å½’ä¸€åŒ–åˆ°0-1
        elif hhi < 0.15:  # ç«äº‰å¸‚åœº
            pattern_type = "competitive_market"
            strength = 1.0 - (hhi / 0.15)
        else:
            return None  # ä¸­ç­‰é›†ä¸­åº¦ï¼Œä¸ç®—æ˜æ˜¾æ¨¡å¼
        
        # æ‰¾å‡ºä¸»è¦è´¡çŒ®è€…ï¼ˆå¸‚åœºä»½é¢æœ€å¤§çš„å‡ å®¶ä¼ä¸šï¼‰
        top_firms = sorted(market_shares.items(), key=lambda x: x[1], reverse=True)[:5]
        contributors = [firm_id for firm_id, _ in top_firms]
        
        return MacroPattern(
            pattern_id=f"market_concentration_{month}",
            pattern_type=pattern_type,
            emergence_month=month,
            strength=strength,
            stability=self._calculate_stability("market_concentration", month),
            micro_contributors=contributors,
            macro_metrics={"hhi": hhi, "top_firm_share": top_firms[0][1] if top_firms else 0},
            description=f"å¸‚åœºé›†ä¸­åº¦æ¨¡å¼ï¼šHHI={hhi:.3f}, {'é«˜åº¦é›†ä¸­' if hhi > 0.25 else 'ç«äº‰å¸‚åœº'}"
        )
    
    def _detect_wealth_inequality(self, month: int) -> Optional[MacroPattern]:
        """æ£€æµ‹è´¢å¯Œä¸å¹³ç­‰æ¨¡å¼"""
        household_behaviors = [b for b in self.micro_behaviors
                              if b.timestamp == month and b.agent_type == "household"]
        
        if not household_behaviors:
            return None
        
        # è·å–è´¢å¯Œæ•°æ®
        wealths = []
        for behavior in household_behaviors:
            if behavior.behavior_type == "wealth_update":
                wealth = behavior.behavior_data.get("wealth", 0)
                wealths.append(wealth)
        
        if len(wealths) < 10:  # éœ€è¦è¶³å¤Ÿæ ·æœ¬
            return None
        
        # è®¡ç®—åŸºå°¼ç³»æ•°
        wealths_sorted = sorted(wealths)
        n = len(wealths_sorted)
        cumsum = np.cumsum(wealths_sorted)
        gini = (2 * np.sum((np.arange(1, n + 1)) * wealths_sorted)) / (n * np.sum(wealths_sorted)) - (n + 1) / n
        
        # åˆ¤æ–­æ˜¯å¦å‡ºç°æ˜æ˜¾çš„ä¸å¹³ç­‰æ¨¡å¼
        if gini > 0.4:  # é«˜åº¦ä¸å¹³ç­‰
            pattern_type = "high_wealth_inequality"
            strength = min(1.0, (gini - 0.4) / 0.3)  # å½’ä¸€åŒ–
        elif gini < 0.2:  # é«˜åº¦å¹³ç­‰
            pattern_type = "wealth_equality"
            strength = 1.0 - (gini / 0.2)
        else:
            return None
        
        # æ‰¾å‡ºæç«¯å€¼ï¼ˆæœ€å¯Œå’Œæœ€ç©·çš„å®¶åº­ï¼‰
        top_10_percent = int(n * 0.1)
        bottom_10_percent = int(n * 0.1)
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦è®°å½•å¯¹åº”çš„agent_id
        
        return MacroPattern(
            pattern_id=f"wealth_inequality_{month}",
            pattern_type=pattern_type,
            emergence_month=month,
            strength=strength,
            stability=self._calculate_stability("wealth_inequality", month),
            micro_contributors=[],  # éœ€è¦ä»behaviorä¸­æå–
            macro_metrics={"gini": gini, "top_10_share": 0, "bottom_10_share": 0},
            description=f"è´¢å¯Œä¸å¹³ç­‰æ¨¡å¼ï¼šåŸºå°¼ç³»æ•°={gini:.3f}"
        )
    
    def _detect_price_correlation(self, month: int) -> Optional[MacroPattern]:
        """æ£€æµ‹ä»·æ ¼ç›¸å…³æ€§æ¨¡å¼ï¼ˆä»·æ ¼è”åŠ¨ã€ä»·æ ¼æ³¡æ²«ç­‰ï¼‰"""
        # è·å–ä»·æ ¼æ•°æ®
        prices_by_product = defaultdict(list)
        
        for behavior in self.micro_behaviors:
            if behavior.timestamp == month and behavior.behavior_type == "price_change":
                product_id = behavior.behavior_data.get("product_id")
                price = behavior.behavior_data.get("price")
                if product_id and price:
                    prices_by_product[product_id].append(price)
        
        if len(prices_by_product) < 5:
            return None
        
        # è®¡ç®—ä»·æ ¼å˜åŒ–çš„ç›¸å…³æ€§çŸ©é˜µ
        price_changes = {}
        for product_id, prices in prices_by_product.items():
            if len(prices) > 1:
                changes = [prices[i] - prices[i-1] for i in range(1, len(prices))]
                price_changes[product_id] = np.mean(changes) if changes else 0
        
        if len(price_changes) < 5:
            return None
        
        # è®¡ç®—å¹³å‡ç›¸å…³æ€§
        changes_list = list(price_changes.values())
        if len(changes_list) < 2:
            return None
        
        # ç®€åŒ–çš„ç›¸å…³æ€§æ£€æµ‹ï¼šå¦‚æœå¤§éƒ¨åˆ†ä»·æ ¼åŒå‘å˜åŒ–ï¼Œè¯´æ˜æœ‰ç›¸å…³æ€§
        positive_changes = sum(1 for c in changes_list if c > 0)
        negative_changes = sum(1 for c in changes_list if c < 0)
        correlation_strength = max(positive_changes, negative_changes) / len(changes_list)
        
        if correlation_strength > 0.7:  # 70%ä»¥ä¸ŠåŒå‘å˜åŒ–
            pattern_type = "price_correlation"
            strength = correlation_strength
            
            return MacroPattern(
                pattern_id=f"price_correlation_{month}",
                pattern_type=pattern_type,
                emergence_month=month,
                strength=strength,
                stability=self._calculate_stability("price_correlation", month),
                micro_contributors=list(price_changes.keys())[:10],
                macro_metrics={"correlation_strength": correlation_strength},
                description=f"ä»·æ ¼ç›¸å…³æ€§æ¨¡å¼ï¼š{correlation_strength:.1%}çš„å•†å“ä»·æ ¼åŒå‘å˜åŒ–"
            )
        
        return None
    
    def _detect_consumption_clusters(self, month: int) -> Optional[MacroPattern]:
        """æ£€æµ‹æ¶ˆè´¹é›†ç¾¤æ¨¡å¼ï¼ˆæ¶ˆè´¹åå¥½åˆ†ç»„ï¼‰"""
        # è·å–æ¶ˆè´¹æ•°æ®
        consumption_vectors = {}
        
        for behavior in self.micro_behaviors:
            if behavior.timestamp == month and behavior.agent_type == "household":
                if behavior.behavior_type == "consume":
                    household_id = behavior.agent_id
                    category = behavior.behavior_data.get("category")
                    amount = behavior.behavior_data.get("amount", 0)
                    
                    if household_id not in consumption_vectors:
                        consumption_vectors[household_id] = defaultdict(float)
                    consumption_vectors[household_id][category] += amount
        
        if len(consumption_vectors) < 10:
            return None
        
        # ä½¿ç”¨èšç±»åˆ†æè¯†åˆ«æ¶ˆè´¹æ¨¡å¼
        # ç®€åŒ–å®ç°ï¼šä½¿ç”¨PCAé™ç»´åèšç±»
        categories = set()
        for vec in consumption_vectors.values():
            categories.update(vec.keys())
        categories = sorted(list(categories))
        
        if len(categories) < 3:
            return None
        
        # æ„å»ºç‰¹å¾çŸ©é˜µ
        X = []
        household_ids = []
        for hh_id, vec in consumption_vectors.items():
            row = [vec.get(cat, 0) for cat in categories]
            X.append(row)
            household_ids.append(hh_id)
        
        X = np.array(X)
        
        # æ ‡å‡†åŒ–
        X_normalized = (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-8)
        
        # èšç±»
        clustering = DBSCAN(eps=0.5, min_samples=3)
        labels = clustering.fit_predict(X_normalized)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„é›†ç¾¤
        unique_labels = set(labels)
        if -1 in unique_labels:
            unique_labels.remove(-1)  # ç§»é™¤å™ªå£°ç‚¹
        
        if len(unique_labels) >= 2:  # è‡³å°‘2ä¸ªé›†ç¾¤
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
            max_cluster_size = max(cluster_sizes)
            strength = max_cluster_size / len(consumption_vectors)
            
            if strength > 0.3:  # æœ€å¤§é›†ç¾¤å æ¯”è¶…è¿‡30%
                return MacroPattern(
                    pattern_id=f"consumption_clusters_{month}",
                    pattern_type="consumption_clustering",
                    emergence_month=month,
                    strength=strength,
                    stability=self._calculate_stability("consumption_clusters", month),
                    micro_contributors=household_ids[:20],
                    macro_metrics={
                        "num_clusters": len(unique_labels),
                        "max_cluster_size": max_cluster_size,
                        "cluster_sizes": cluster_sizes
                    },
                    description=f"æ¶ˆè´¹é›†ç¾¤æ¨¡å¼ï¼šè¯†åˆ«å‡º{len(unique_labels)}ä¸ªæ¶ˆè´¹åå¥½é›†ç¾¤"
                )
        
        return None
    
    def _detect_innovation_diffusion(self, month: int) -> Optional[MacroPattern]:
        """æ£€æµ‹åˆ›æ–°æ‰©æ•£æ¨¡å¼ï¼ˆåˆ›æ–°å¦‚ä½•ä¼ æ’­ï¼‰"""
        # è·å–åˆ›æ–°äº‹ä»¶
        innovation_events = []
        for behavior in self.micro_behaviors:
            if behavior.timestamp == month and behavior.behavior_type == "innovate":
                innovation_events.append(behavior)
        
        if len(innovation_events) < 3:
            return None
        
        # åˆ†æåˆ›æ–°çš„ç©ºé—´/æ—¶é—´åˆ†å¸ƒ
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥åˆ›æ–°æ˜¯å¦é›†ä¸­åœ¨æŸäº›ä¼ä¸š
        innovating_firms = [b.agent_id for b in innovation_events]
        firm_counts = defaultdict(int)
        for firm_id in innovating_firms:
            firm_counts[firm_id] += 1
        
        # å¦‚æœåˆ›æ–°é›†ä¸­åœ¨å°‘æ•°ä¼ä¸šï¼Œè¯´æ˜æœ‰æ‰©æ•£æ¨¡å¼
        if len(firm_counts) < len(innovating_firms) * 0.5:  # å°‘äº50%çš„ä¼ä¸šæœ‰åˆ›æ–°
            concentration = len(firm_counts) / len(innovating_firms) if innovating_firms else 0
            strength = 1.0 - concentration
            
            return MacroPattern(
                pattern_id=f"innovation_diffusion_{month}",
                pattern_type="innovation_clustering",
                emergence_month=month,
                strength=strength,
                stability=self._calculate_stability("innovation_diffusion", month),
                micro_contributors=list(firm_counts.keys()),
                macro_metrics={
                    "num_innovating_firms": len(firm_counts),
                    "total_innovations": len(innovation_events),
                    "concentration": concentration
                },
                description=f"åˆ›æ–°æ‰©æ•£æ¨¡å¼ï¼šåˆ›æ–°é›†ä¸­åœ¨{len(firm_counts)}å®¶ä¼ä¸š"
            )
        
        return None
    
    def _calculate_stability(self, pattern_type: str, month: int, window: int = 3) -> float:
        """è®¡ç®—æ¨¡å¼ç¨³å®šæ€§ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰"""
        if month < window:
            return 0.5  # æ•°æ®ä¸è¶³ï¼Œè¿”å›ä¸­ç­‰ç¨³å®šæ€§
        
        # æ£€æŸ¥å‰å‡ ä¸ªæœˆæ˜¯å¦ä¹Ÿæœ‰ç±»ä¼¼æ¨¡å¼
        recent_patterns = [p for p in self.macro_patterns 
                          if p.pattern_type == pattern_type 
                          and month - window <= p.emergence_month < month]
        
        if not recent_patterns:
            return 0.3  # æ–°å‡ºç°çš„æ¨¡å¼ï¼Œç¨³å®šæ€§è¾ƒä½
        
        # ç¨³å®šæ€§ = è¿ç»­å‡ºç°çš„æœˆä»½æ•° / çª—å£å¤§å°
        stability = len(recent_patterns) / window
        return min(1.0, stability)
    
    def _calculate_emergence_metrics(self, month: int) -> EmergenceMetrics:
        """è®¡ç®—æ¶Œç°æŒ‡æ ‡"""
        # 1. æ¶Œç°å¼ºåº¦ï¼šåŸºäºæ¨¡å¼æ•°é‡å’Œå¼ºåº¦
        recent_patterns = [p for p in self.macro_patterns if p.emergence_month == month]
        if recent_patterns:
            emergence_strength = np.mean([p.strength for p in recent_patterns])
        else:
            emergence_strength = 0.0
        
        # 2. ä¸´ç•Œç‚¹æ£€æµ‹ï¼ˆç›¸å˜ï¼‰
        critical_point = self._detect_critical_point(month)
        
        # 3. åºå‚é‡ï¼šç³»ç»Ÿæœ‰åºç¨‹åº¦çš„åº¦é‡
        order_parameter = self._calculate_order_parameter(month)
        
        # 4. å…³è”é•¿åº¦ï¼šç³»ç»Ÿå„éƒ¨åˆ†çš„ç›¸å…³æ€§èŒƒå›´
        correlation_length = self._calculate_correlation_length(month)
        
        # 5. è‡ªç»„ç»‡æŒ‡æ•°
        self_org_index = self._calculate_self_organization_index(month)
        
        return EmergenceMetrics(
            emergence_strength=emergence_strength,
            critical_point=critical_point,
            order_parameter=order_parameter,
            correlation_length=correlation_length,
            self_organization_index=self_org_index
        )
    
    def _detect_critical_point(self, month: int, window: int = 5) -> Optional[int]:
        """æ£€æµ‹ä¸´ç•Œç‚¹ï¼ˆç›¸å˜å‘ç”Ÿçš„æœˆä»½ï¼‰"""
        if month < window * 2:
            return None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æŒ‡æ ‡å‘ç”Ÿçªå˜
        # ä¾‹å¦‚ï¼šåŸºå°¼ç³»æ•°ã€å¸‚åœºé›†ä¸­åº¦ç­‰çš„çªç„¶å˜åŒ–
        
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥æ¨¡å¼æ•°é‡çš„çªå˜
        pattern_counts = []
        for m in range(max(1, month - window), month + 1):
            count = len([p for p in self.macro_patterns if p.emergence_month == m])
            pattern_counts.append(count)
        
        if len(pattern_counts) < window:
            return None
        
        # æ£€æµ‹çªå˜ç‚¹
        for i in range(1, len(pattern_counts)):
            if pattern_counts[i] > pattern_counts[i-1] * 2:  # æ¨¡å¼æ•°é‡ç¿»å€
                return month - window + i
        
        return None
    
    def _calculate_order_parameter(self, month: int) -> float:
        """è®¡ç®—åºå‚é‡ï¼ˆç³»ç»Ÿæœ‰åºç¨‹åº¦ï¼‰"""
        # åºå‚é‡å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼è®¡ç®—
        # ä¾‹å¦‚ï¼šå¸‚åœºé›†ä¸­åº¦ã€ä»·æ ¼ç›¸å…³æ€§ã€æ¶ˆè´¹é›†ç¾¤åº¦ç­‰
        
        recent_patterns = [p for p in self.macro_patterns if p.emergence_month == month]
        if not recent_patterns:
            return 0.0
        
        # ç®€åŒ–ï¼šä½¿ç”¨æ¨¡å¼å¼ºåº¦çš„åŠ æƒå¹³å‡
        order_parameter = np.mean([p.strength * p.stability for p in recent_patterns])
        return order_parameter
    
    def _calculate_correlation_length(self, month: int) -> float:
        """è®¡ç®—å…³è”é•¿åº¦"""
        # å…³è”é•¿åº¦ï¼šç³»ç»Ÿå„éƒ¨åˆ†çš„ç›¸å…³æ€§èŒƒå›´
        # å¯ä»¥é€šè¿‡åˆ†ææ™ºèƒ½ä½“ä¹‹é—´çš„ç›¸å…³æ€§æ¥è®¡ç®—
        
        # ç®€åŒ–å®ç°ï¼šåŸºäºè¡Œä¸ºçš„ç›¸å…³æ€§
        behaviors = [b for b in self.micro_behaviors if b.timestamp == month]
        if len(behaviors) < 10:
            return 0.0
        
        # è®¡ç®—è¡Œä¸ºç±»å‹çš„å¤šæ ·æ€§
        behavior_types = set(b.behavior_type for b in behaviors)
        diversity = len(behavior_types) / max(1, len(behaviors))
        
        # å…³è”é•¿åº¦ä¸å¤šæ ·æ€§æˆåæ¯”
        correlation_length = 1.0 - diversity
        return max(0.0, min(1.0, correlation_length))
    
    def _calculate_self_organization_index(self, month: int) -> float:
        """è®¡ç®—è‡ªç»„ç»‡æŒ‡æ•°"""
        # è‡ªç»„ç»‡æŒ‡æ•°ï¼šç³»ç»Ÿè‡ªå‘å½¢æˆç»“æ„çš„ç¨‹åº¦
        # å¯ä»¥é€šè¿‡åˆ†æç»“æ„çš„å¤æ‚æ€§å’Œæœ‰åºæ€§æ¥è®¡ç®—
        
        # ç®€åŒ–å®ç°ï¼šåŸºäºæ¨¡å¼æ•°é‡å’Œç¨³å®šæ€§
        recent_patterns = [p for p in self.macro_patterns if p.emergence_month == month]
        if not recent_patterns:
            return 0.0
        
        # è‡ªç»„ç»‡æŒ‡æ•° = æ¨¡å¼æ•°é‡ Ã— å¹³å‡ç¨³å®šæ€§ Ã— å¹³å‡å¼ºåº¦
        avg_stability = np.mean([p.stability for p in recent_patterns])
        avg_strength = np.mean([p.strength for p in recent_patterns])
        num_patterns = len(recent_patterns)
        
        # å½’ä¸€åŒ–
        self_org_index = (num_patterns / 10.0) * avg_stability * avg_strength
        return min(1.0, self_org_index)
    
    def _detect_phase_transitions(self, month: int) -> List[Dict[str, Any]]:
        """æ£€æµ‹ç›¸å˜"""
        transitions = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸´ç•Œç‚¹
        critical_point = self._detect_critical_point(month)
        if critical_point and critical_point == month:
            transitions.append({
                "type": "critical_transition",
                "month": month,
                "description": "æ£€æµ‹åˆ°ç³»ç»Ÿä¸´ç•Œç‚¹ï¼Œå¯èƒ½å‘ç”Ÿç›¸å˜",
                "indicators": {
                    "order_parameter_change": 0,  # éœ€è¦è®¡ç®—
                    "pattern_count_change": 0
                }
            })
        
        return transitions
    
    def _detect_self_organization(self, month: int) -> List[Dict[str, Any]]:
        """æ£€æµ‹è‡ªç»„ç»‡ç»“æ„"""
        structures = []
        
        # æ£€æµ‹æ¶ˆè´¹é›†ç¾¤
        cluster_patterns = [p for p in self.macro_patterns 
                           if p.pattern_type == "consumption_clustering" 
                           and p.emergence_month == month]
        
        for pattern in cluster_patterns:
            structures.append({
                "type": "consumption_cluster",
                "month": month,
                "pattern_id": pattern.pattern_id,
                "description": "è‡ªå‘å½¢æˆçš„æ¶ˆè´¹åå¥½é›†ç¾¤",
                "metrics": pattern.macro_metrics
            })
        
        # æ£€æµ‹å¸‚åœºç»“æ„
        market_patterns = [p for p in self.macro_patterns
                          if "market" in p.pattern_type
                          and p.emergence_month == month]
        
        for pattern in market_patterns:
            structures.append({
                "type": "market_structure",
                "month": month,
                "pattern_id": pattern.pattern_id,
                "description": "è‡ªå‘å½¢æˆçš„å¸‚åœºç»“æ„",
                "metrics": pattern.macro_metrics
            })
        
        return structures
    
    def _analyze_micro_macro_mapping(self, patterns: List[MacroPattern]) -> Dict[str, Dict[str, Any]]:
        """åˆ†æå¾®è§‚-å®è§‚æ˜ å°„å…³ç³»"""
        mapping = {}
        
        for pattern in patterns:
            # åˆ†ææ¯ä¸ªæ¨¡å¼ç”±å“ªäº›ä¸ªä½“è¡Œä¸ºè´¡çŒ®
            contributors = pattern.micro_contributors
            
            # è®¡ç®—è´¡çŒ®æƒé‡
            contribution_weights = {}
            if contributors:
                # ç®€åŒ–ï¼šå¹³å‡åˆ†é…æƒé‡
                weight = 1.0 / len(contributors)
                for contributor in contributors:
                    contribution_weights[contributor] = weight
            
            # åˆ†ææ¶Œç°æœºåˆ¶
            mechanism = self._identify_emergence_mechanism(pattern)
            
            mapping[pattern.pattern_id] = {
                "micro_contributors": contributors,
                "contribution_weights": contribution_weights,
                "emergence_mechanism": mechanism,
                "contribution_analysis": self._analyze_contributions(pattern)
            }
        
        return mapping
    
    def _identify_emergence_mechanism(self, pattern: MacroPattern) -> str:
        """è¯†åˆ«æ¶Œç°æœºåˆ¶"""
        # æ ¹æ®æ¨¡å¼ç±»å‹å’Œç‰¹å¾è¯†åˆ«æœºåˆ¶
        
        if "concentration" in pattern.pattern_type:
            return "æ­£åé¦ˆæœºåˆ¶ï¼šæˆåŠŸè€…è·å¾—æ›´å¤šèµ„æºï¼Œå¯¼è‡´å¸‚åœºé›†ä¸­"
        elif "inequality" in pattern.pattern_type:
            return "ç´¯ç§¯ä¼˜åŠ¿ï¼šåˆå§‹å·®å¼‚é€šè¿‡å¤åˆ©æ•ˆåº”æ”¾å¤§"
        elif "correlation" in pattern.pattern_type:
            return "ä¿¡æ¯ä¼ æ’­ï¼šä»·æ ¼ä¿¡æ¯é€šè¿‡å¸‚åœºç½‘ç»œä¼ æ’­"
        elif "cluster" in pattern.pattern_type:
            return "åŒè´¨æ€§åå¥½ï¼šç›¸ä¼¼ä¸ªä½“å½¢æˆé›†ç¾¤"
        elif "diffusion" in pattern.pattern_type:
            return "ç½‘ç»œæ•ˆåº”ï¼šåˆ›æ–°é€šè¿‡ç¤¾ä¼šç½‘ç»œæ‰©æ•£"
        else:
            return "å¤æ‚äº¤äº’ï¼šå¤šä¸ªå› ç´ å…±åŒä½œç”¨"
    
    def _analyze_contributions(self, pattern: MacroPattern) -> Dict[str, Any]:
        """åˆ†æä¸ªä½“è´¡çŒ®"""
        # åˆ†æå“ªäº›ä¸ªä½“å¯¹æ¨¡å¼å½¢æˆè´¡çŒ®æœ€å¤§
        
        contributors = pattern.micro_contributors
        if not contributors:
            return {"top_contributors": [], "contribution_distribution": "uniform"}
        
        # ç®€åŒ–åˆ†æ
        return {
            "top_contributors": contributors[:5],
            "contribution_distribution": "power_law" if len(contributors) > 10 else "uniform",
            "contribution_inequality": 0.5  # éœ€è¦å®é™…è®¡ç®—
        }
    
    def _generate_visualizations(self, month: int) -> Dict[str, str]:
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        visualizations = {}
        
        # 1. æ¨¡å¼æ¼”åŒ–å›¾
        pattern_evolution_path = self._plot_pattern_evolution(month)
        visualizations["pattern_evolution"] = pattern_evolution_path
        
        # 2. ç›¸å›¾
        phase_diagram_path = self._plot_phase_diagram(month)
        visualizations["phase_diagram"] = phase_diagram_path
        
        # 3. å¾®è§‚-å®è§‚æ˜ å°„å›¾
        micro_macro_path = self._plot_micro_macro_mapping(month)
        visualizations["micro_macro_mapping"] = micro_macro_path
        
        return visualizations
    
    def _plot_pattern_evolution(self, month: int) -> str:
        """ç»˜åˆ¶æ¨¡å¼æ¼”åŒ–å›¾"""
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # æ”¶é›†å†å²æ•°æ®
        months = sorted(set(p.emergence_month for p in self.macro_patterns))
        pattern_counts = [len([p for p in self.macro_patterns if p.emergence_month == m]) 
                         for m in months]
        
        ax.plot(months, pattern_counts, marker='o', linewidth=2)
        ax.set_xlabel('Month')
        ax.set_ylabel('Number of Patterns')
        ax.set_title('Macro Pattern Evolution Over Time')
        ax.grid(True, alpha=0.3)
        
        path = f"{self.output_dir}/pattern_evolution_month_{month}.png"
        plt.savefig(path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return path
    
    def _plot_phase_diagram(self, month: int) -> str:
        """ç»˜åˆ¶ç›¸å›¾"""
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # æ”¶é›†æ•°æ®
        months = sorted(self.emergence_metrics.keys())
        order_params = [self.emergence_metrics[m].order_parameter for m in months]
        self_org_indices = [self.emergence_metrics[m].self_organization_index for m in months]
        
        scatter = ax.scatter(order_params, self_org_indices, c=months, cmap='viridis', s=100)
        ax.set_xlabel('Order Parameter')
        ax.set_ylabel('Self-Organization Index')
        ax.set_title('Phase Diagram: System State Evolution')
        plt.colorbar(scatter, label='Month')
        ax.grid(True, alpha=0.3)
        
        path = f"{self.output_dir}/phase_diagram_month_{month}.png"
        plt.savefig(path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return path
    
    def _plot_micro_macro_mapping(self, month: int) -> str:
        """ç»˜åˆ¶å¾®è§‚-å®è§‚æ˜ å°„å›¾"""
        # ç®€åŒ–å®ç°ï¼šå±•ç¤ºæ¨¡å¼ä¸è´¡çŒ®è€…çš„å…³ç³»
        fig, ax = plt.subplots(figsize=(12, 8))
        
        recent_patterns = [p for p in self.macro_patterns if p.emergence_month == month]
        
        if not recent_patterns:
            ax.text(0.5, 0.5, 'No patterns detected', ha='center', va='center')
        else:
            # ç»˜åˆ¶æ¨¡å¼-è´¡çŒ®è€…ç½‘ç»œ
            # ç®€åŒ–ï¼šæ¡å½¢å›¾æ˜¾ç¤ºæ¯ä¸ªæ¨¡å¼çš„è´¡çŒ®è€…æ•°é‡
            pattern_names = [p.pattern_id[:20] for p in recent_patterns]
            contributor_counts = [len(p.micro_contributors) for p in recent_patterns]
            
            ax.barh(pattern_names, contributor_counts)
            ax.set_xlabel('Number of Micro Contributors')
            ax.set_title('Micro-Macro Mapping: Contributors per Pattern')
        
        path = f"{self.output_dir}/micro_macro_mapping_month_{month}.png"
        plt.savefig(path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return path
    
    def _generate_summary(self, patterns: List[MacroPattern], 
                         metrics: EmergenceMetrics,
                         phase_transitions: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæ‘˜è¦"""
        summary = f"""
æ¶Œç°è¡Œä¸ºåˆ†ææ‘˜è¦ï¼ˆç¬¬ {metrics.emergence_strength:.2%} æ¶Œç°å¼ºåº¦ï¼‰

è¯†åˆ«çš„å®è§‚æ¨¡å¼ï¼š{len(patterns)} ä¸ª
- {'; '.join([p.pattern_type for p in patterns[:3]])}

æ¶Œç°æŒ‡æ ‡ï¼š
- åºå‚é‡ï¼š{metrics.order_parameter:.3f}
- è‡ªç»„ç»‡æŒ‡æ•°ï¼š{metrics.self_organization_index:.3f}
- å…³è”é•¿åº¦ï¼š{metrics.correlation_length:.3f}
- ä¸´ç•Œç‚¹ï¼š{'æ˜¯' if metrics.critical_point else 'å¦'}

ç›¸å˜æ£€æµ‹ï¼š{len(phase_transitions)} ä¸ª
"""
        return summary.strip()
    
    def _pattern_to_dict(self, pattern: MacroPattern) -> Dict[str, Any]:
        """å°†æ¨¡å¼å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "pattern_id": pattern.pattern_id,
            "pattern_type": pattern.pattern_type,
            "emergence_month": pattern.emergence_month,
            "strength": pattern.strength,
            "stability": pattern.stability,
            "micro_contributors": pattern.micro_contributors,
            "macro_metrics": pattern.macro_metrics,
            "description": pattern.description
        }
    
    def _metrics_to_dict(self, metrics: EmergenceMetrics) -> Dict[str, Any]:
        """å°†æŒ‡æ ‡å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "emergence_strength": metrics.emergence_strength,
            "critical_point": metrics.critical_point,
            "order_parameter": metrics.order_parameter,
            "correlation_length": metrics.correlation_length,
            "self_organization_index": metrics.self_organization_index
        }
    
    def _save_report(self, report: Dict[str, Any], month: int):
        """ä¿å­˜æŠ¥å‘Š"""
        report_path = f"{self.output_dir}/emergence_report_month_{month}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"ğŸ“„ æ¶Œç°è¡Œä¸ºæŠ¥å‘Šå·²ä¿å­˜: {report_path}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    analyzer = EmergentBehaviorAnalyzer()
    
    # è®°å½•ä¸€äº›ç¤ºä¾‹è¡Œä¸º
    analyzer.record_micro_behavior(
        agent_id="household_1",
        agent_type="household",
        month=1,
        behavior_type="consume",
        behavior_data={"category": "food", "amount": 100}
    )
    
    # åˆ†ææ¶Œç°è¡Œä¸º
    report = analyzer.analyze_emergence(month=1)
    print(json.dumps(report, indent=2, ensure_ascii=False))

